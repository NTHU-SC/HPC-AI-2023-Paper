\section{Conclusion}
This paper has detailed our participation in the 2023 High-Performance Computing and Artificial Intelligence (HPC-AI) Asia-Pacific Competition, a challenging and enriching experience that tested our skills and knowledge in the realms of high-performance computing and AI. Our team's efforts were focused on two main challenges: optimizing the Climate Prediction Model MPAS to enhance simulation speed on CPUs, and accelerating the Large Language Model Bloom to minimize generation time per token on GPUs.

Our experiments, conducted on four different supercomputer systems, including GADI in Australia and ASPIRE-2A in Singapore, as well as Taiwania-2 and Taiwania-3 in Taiwan, allowed us to gather comprehensive data and compare results across different platforms.

In MPAS, we achieved a speedup of 1.34 times. Given the constraint of being unable to modify the source code, we optimized all aspects of the software environment and load balancing. While the numerical reduction in simulation time may not be a lot, we believe that these configurations will yield more substantial benefits when applied to simulations with larger time scales.

On the other hand, we significantly improved the performance of the quantized bloom-deepspeed-inference-int8 model, making its inference process 11.4 times faster than the original model's batch inference on the Gadi supercomputer. We observed that the primary bottleneck is the limited GPU RAM. As we are unable to alter the model or the inference framework, we believe that using A100 GPUs and finding better methods to achieve higher parallelism will help us overcome more challenges.

Finally, our participation in the 2023 HPC-AI competition has been a profound learning experience, providing us with the opportunity to apply our skills in a real-world context.
\label{sec:conc}

